TODO – framework:
0.    [DONE] ogarnąć gammaGLM (daje wartości zero lub mniejsze z inverse linkiem - trzeba poprawić, gdyż wywala błąd na metryce Tweedie z p = 2)
        -> wystarczyło zamieniać ujemne wartości na dodatnie
1.    [DONE] dopisać add_constant do StatsmodelGLM
1.5.  [DONE] Przepisać kalibrację tak, aby korzystała z modeli predykcyjnych z pipeline'u ds - może jakieś wielodziedziczenie (wystarczy coś zrobić z dwiema zmiennymi: target_col i pred_col).
2.    [ZAWIESZONE] Dodać statsmodels.discrete.count_model.ZeroInflatedGeneralizedPoisson dla częstotliwości
3.    [DONE] Ogarnąć wszystko dla TweediegoGLM (w przypadku Tweediego w kalibracji trzeba będzie zrobić mikro hyperopta – już nie trzeba, bo nie da się kalibrować dla powe linka - ujemne wartości w regresji -> wywala błąd)
4.    [DONE] Sprawdzić poprawność obliczania giniego (gini nie powinien być równy 1 dla trywialnego modelu - constant)
5.    [DONE] Wykres krzywej lorentza
6.    [DONE] Zdebugować hyperopta dla parametru alpha
7.    [DONE] Rozdzielić w p07_ds zbiór próbkowy na train/val - logować metryki na tych dwóch zbiorach
8.    [DONE] Napisać p09_train, który w analogii do p09_test, obliczy nieskalibrowane i skalibrowane predykcje na całym zbiorze treningowym (train_keys) - logować do mlflow
9.    [DONE] Napisać outlier_policy: keep, clip, drop - dla sample, calib i test (uwspólnić kod)
10.   [DONE] Dodać zmienne binarne dla przedziałów pojemności silnika itp.
10.1. [DONE] Transformować feature Area: we choose a continuous (log-linear) feature component for {A, . . . , F} --> {1, . . . , 6}
10.2. [DONE] Napisać onehot encoder, w którym będzie można wybrać kategorie do usunięcia
11.1. [DONE] NormalizedConcentrationIndex - pozmnieniać nazwy
11.2. [DONE] Uruchomić dobry eksperyment, bo potrzeba sprawdzić CI i mieć dobre dane do innych wykresów i indeksów
12.   [DONE] Policzyć średni target w kubełkach cross walidacji - capping do do 300 tys.
13.1  [DONE] Dodać wykres Concentraion Curve (ordered lorentz) do mlflow
13.2  [DONE] Zrobić wykres uśredniający wszystkie Concentraion Curves dla foldów cross walidacji
14.   [DONE] Zestawić na wykresie krzywą lorentza (tę z samą predykcją bez true values) i Concentraion Curve
14.1  [DONE] Zrobić to samo dla pure predictions (tak jak ewaluacja w p09_test)
15.   [DONE] Dodać wykresy krzywej skumulowanej kalibracji
15.1  [DONE] Dodać własne indeksy kalibracji (CCI, COI i CUI)
16.   [DONE] Opracować wykres średniego targetu w percentylach / predykcji
16.1  [DONE] zrobić w parameters.yml słownik summary z przedziałami y_min, y_max dla wykresu
17.   [DONE] Zaimplementować ABC z artykułu Testing for auto-calibration
18.   [DONE] Rekalibracje lokalne:
18.1  [DONE] Uśrednianie w obrębie równych binów
18.2  [DONE] Local polynomial regression - skmisc.loess.loess_model
18.3. [DONE] GLM w lokalnym otoczeniu - PDF: Does autocalibration improve goodness of lift (2022) Ciato
19.   [DONE] Selekcja cech za pomocą GLM (Poisson, Gamma... zamiast Lasso) - użyć https://glm-tools.github.io/pyglmnet/api.html
20.   [DONE] Sprawdzić wszystko dla Poissona
20.1  [DONE] Znaleźć błąd w ewNCI
21.   [DONE] Dummy regressor - stała wartość jako predykcja (średnia targetu)
22.   [DONE] Zdebugować PCA
23.   [DONE] Polynomial features
24.   [DONE] Stratified sampling (bez CV) - heurystyka dodawania do kubełków train/calib/test, aby zgadzały się ważone sumy targetu
25.   [DONE] Wyświetlanie numeru partycji w logach hyperopt
26.   [DONE] Logowanie do głównego mlflow_run_id tabelki wyników hyperopta - dwie tabelki:
26.1. [DONE] Dla najlepszych trials wyniki wszystkich foldów train/val, średnia i std
26.2. [DONE] Wspólna tabelka dla najlepszych trials: wartości hiperparametrów z odpowiadającymi wynikami (mean i std)
27.   [DONE] Dopisać w IsotonicLikeCalibrationModel ustawianie _set_y_min i _set_y_max dla parametrów clip_low_bin i clip_high_bin
28.   [DONE] Dodać karę do hyperopta za przeuczenie

___________________________________________________________________________________


./run_experiment.sh sev_002_statsmodels_glm_inverse_features_engineering all_to_test --other-pipeline de_to_test
./run_experiment.sh sev_002_statsmodels_glm_inverse_features_engineering de_to_test --from-run-name run_0003_intercept_10

./run_experiment.sh sev_007_pyglmnet_hyperopt all_to_test --other-pipeline de_to_test
./run_experiment.sh sev_008_calibration_sev_007_run_0001 all_to_test --other-pipeline clb_test
./run_experiment.sh sev_008_calibration_sev_007_run_0001  summary --run-name run_0001_no_calib run_0799_calib_EqualBinsMeans_n_bins_10 run_0905_calib_LocalPolynomialRegression_span_1_degree_1 run_0673_calib_LocalStatsmodelsGLM_inverse_link_frac_1_gaussian_kernel run_0111_calib_IsotonicRegression_clip_low_0.06_clip_high_0.01 run_0644_calib_CenteredIsotonicRegression_clip_low_0.3_clip_high_0.14

'run_0001_no_calib', 'run_0799_calib_EqualBinsMeans_n_bins_10', 'run_0905_calib_LocalPolynomialRegression_span_1_degree_1', 'run_0673_calib_LocalStatsmodelsGLM_inverse_link_frac_1_gaussian_kernel', 'run_0111_calib_IsotonicRegression_clip_low_0.06_clip_high_0.01',

./run_experiment.sh sev_008_calibration_sev_007_run_0001  summary --run-name run_0644_calib_CenteredIsotonicRegression_clip_low_0.3_clip_high_0.14 run_0904_calib_LocalPolynomialRegression_span_1_degree_0 run_0906_calib_LocalPolynomialRegression_span_1_degree_2 run_0873_calib_LocalPolynomialRegression_span_0.25_degree_1 run_0740_calib_LocalStatsmodelsGLM_log_link_frac_0.5_gaussian_kernel run_0320_calib_IsotonicRegression_clip_low_0.3_clip_high_0.14 run_0005_calib_IsotonicRegression_clip_high_0.03 run_0613_calib_CenteredIsotonicRegression_clip_low_0.2_clip_high_0.3 run_0635_calib_CenteredIsotonicRegression_clip_low_0.3_clip_high_0.03 run_0619_calib_CenteredIsotonicRegression_clip_low_0.25_clip_high_0.05

./run_experiment.sh sev_009_pyglmnet_hyperopt all_to_test --other-pipeline smpl_to_test


./run_experiment.sh sev_010_calibration_sev_007_run_0001 all_to_smpl --run-name run_0001_no_calib

./run_experiment.sh sev_010_calibration_sev_007_run_0001 clb_test

./run_experiment.sh sev_010_calibration_sev_007_run_0001 summary --run-name run_0001_calib_Pure run_0799_calib_EqualBinsMeans_n_bins_10 run_0721_calib_LocalStatsmodelsGLM_inverse_link_frac_1_triangular_kernel run_0744_calib_LocalStatsmodelsGLM_log_link_frac_0.9_gaussian_kernel run_0738_calib_LocalStatsmodelsGLM_log_link_frac_0.3_gaussian_kernel run_0896_calib_LocalPolynomialRegression_span_0.8_degree_0 run_0111_calib_IsotonicRegression_clip_low_0.06_clip_high_0.01 run_0289_calib_IsotonicRegression_clip_low_0.2_clip_high_0.3 run_0644_calib_CenteredIsotonicRegression_clip_low_0.3_clip_high_0.14 run_0904_calib_LocalPolynomialRegression_span_1_degree_0 run_0906_calib_LocalPolynomialRegression_span_1_degree_2 run_0873_calib_LocalPolynomialRegression_span_0.25_degree_1 run_0740_calib_LocalStatsmodelsGLM_log_link_frac_0.5_gaussian_kernel run_0320_calib_IsotonicRegression_clip_low_0.3_clip_high_0.14 run_0005_calib_IsotonicRegression_clip_high_0.03 run_0613_calib_CenteredIsotonicRegression_clip_low_0.2_clip_high_0.3 run_0635_calib_CenteredIsotonicRegression_clip_low_0.3_clip_high_0.03 run_0619_calib_CenteredIsotonicRegression_clip_low_0.25_clip_high_0.05


X.    BACKLOG Dodać hyperopta dla modeli kalibracji

X.    BACKLOG Dodać RGLMNet - bo tam jest L1 dla Poisson i obsługa wag (wagi nie są obsługiwne w pyglmnet)
X.    [CANCELED] Model łączący modele na częstotliwość i średnią szkodę.


TODO - eksperymenty - severity:
0.    [DONE] Dummy regressor
1.    [DONE] Wuthrich features + inverse link
2.    [DONE] inverse link + różne skalowania
3.    TODO statsmodels log link + różne skalowania
4.    TODO statsmodels log link + feature selection (liczba cech + pyglmnet)
5.    TODO statsmodels log link: outliers (policy + threshold)
6.    TODO sklearn log link: L2
7.    TODO pyglm log link: L1 i L2
8.    TOOO kalibracja (3 metody) wybranych modeli z 0.-7.

TODO - eksperymenty - frequency:
0.    TODO Dummy regressor
1.    TODO Wuthrich features + inverse link
    TODO statsmodels log link + różne skalowania
    TODO statsmodels log link + feature selection (liczba cech + pyglmnet)
    TODO statsmodels log link: outliers (policy + threshold)
    TODO sklearn log link: L2
    TODO pyglm log link: L1 i L2
    TOOO kalibracja (3 metody) wybranych modeli z
    TODO target ratio

TODO - tekst:
0. Ewaluacja (gini, lorentz, CC, krzywa kalibracji)
