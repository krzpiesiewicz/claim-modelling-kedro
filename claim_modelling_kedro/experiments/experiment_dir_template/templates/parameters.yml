model:
  name: test-model
  author: Krzysztof Piesiewicz
  short_description: Poisson GLM for claim frequency
  full_description: GLM from stats models with Poisson link function
  target: frequency # 'claim_number', 'total_claims_amount', 'frequency','severity',
                    # 'positive_claims_amount', 'positive_severity'
  type: GLM
  model: SklearnPoissonGLM # 'StatsmodelsPoissonGLM', 'StatsmodelsGammaGLM',
    # 'SklearnPoissonGLM', 'SklearnGammaGLM', 'SklearnTweedieGLM'


data:
  raw_files:
    policy_id_col: IDpol
    claims_number_col: ClaimNb
    claims_amount_col: ClaimAmount
    exposure_col: Exposure
  claims_number_target_col: ClaimNb_TRG
  claims_total_amount_target_col: ClaimTotalAmount_TRG
  claims_freq_target_col: ClaimFreq_TRG
  claims_severity_target_col: ClaimSeverity_TRG
  claims_number_pred_col: ClaimNb_PRED
  claims_total_amount_pred_col: ClaimTotalAmount_PRED
  claims_freq_pred_col: ClaimFreq_PRED
  claims_severity_pred_col: ClaimSeverity_PRED
  policy_exposure_col: Exposure
  policy_id_col: IDpol
  split_random_seed: 1
  calib_size: 0.1 # [0,1) - the part of policies used for model calibration
    # if calib_size is None or zero, then calibration.enabled has to be set to False
  test_size: 0.1 # (0, 1) the part of policies used for test if cross_validation.enabled is False
    # if cross_validation.enabled is True, then test_size param is ignored (test_size = data_size / folds).
    # test_size has to be greater than 0.
    # => train_size = 1 - calib_data_size - calib_data_size (train_size has to be greater than 0)
  cross_validation:
    enabled: True # whether to use cross-validation
    folds: 3 # the number of folds in cross-validation (repetitions of data splitting)
    # minimum number of folds is 3
    # test_size = 1 / folds
    # calib_size = 1 / folds
    # train_size = 1 - calib_size - test_size



sampling:
  use_calib_data: False # whether to use also the calibration data for sampling
  random_seed: 1
  n_obs: 50000 # the number of samples which are used to train a model
    # if n_obs is None, then all training data is used
  target_ratio: 0.5 # the ratio of nonzero samples
  allow_lower_ratio: True # allow the ratio of nonzero samples to be lower than target_ratio
  include_zeros: True # include zero values of target in a sample
  lower_bound: 0
  upper_bound: 100


data_engineering:
  mlflow_run_id: # If provided a MLFLow run id, the de models are saved to / downloaded from the MLflow run
  custom_features:
    enabled: True # whether to use custom features
    features: # the list of custom features
      - name: "DrivAgeCategory"
        type: "categorical"
        single_column: False
        description: "The category of driver's age"
        model_class: claim_models.pipelines.p06_data_engineering.utils.custom_features.DrivAgeCategoryCreatorModel
      # Example entry below
#      - name: str # e.g. "MyCustomFeature"
#        type: str # "categorical" or "numerical"
#        single_column: bool # whether the model generates feature as a single column
#        description: str # e.g. "My custom feature is a combination of two other features"
#        model_class: str # e.g. "p06_data_engineering.utils.custom_features.MyCustomFeatureCreatorModel"
  reduce_categories:
    enabled: True # whether to reduce the number of categories in a feature
    max_categories: # the maximum number of categories in a feature
    join_exceeding_max_categories: "other" # (str) if nonempty, join categories exceeding max_categories
    # into one category with the name given in this parameter
    min_frequency: 30 # the minimum frequency of a category in a feature
    join_infrequent: "other" # (str) if nonempty, join categories with frequency lower than min_frequency
      # into one category with the name given in this parameter
      # ATTENTION: if both join_exceeding_max_categories and join_infrequent are provided,
      # the join_exceeding_max_categories is used instead of join_infrequent.
  cat_ftrs_imputer:
    enabled: True # whether to use the imputer
    strategy: constant # 'most_frequent', 'constant'
    fill_value: unknown # the value used to fill missing values
  num_ftrs_imputer:
    enabled: True # whether to use the imputer
    strategy: constant # 'mean', 'median', 'most_frequent', 'constant'
    fill_value: 0 # the value used to fill missing values
  ohe:
    enabled: True # whether to use the OHE
    drop: if_binary # 'first' or 'if_binary'
    max_categories: # (int) the maximum number of categories in a feature
    min_frequency: # (int) the minimum frequency of a category in a feature
  scaler:
    enabled: True # whether to use the scaler


data_science:
  mlflow_run_id: # If provided a MLFLow run id, the selector and prediction model are saved to /
    # downloaded from the MLflow run
  feature_selection:
    enabled: True # whether to use the feature selection
    max_n_features: 100 # the number of features used in the model; if empty, "auto" is used
    min_importance: 0.0001 # the minimum importance of a feature
    max_iter: 100 # the maximum number of iterations
    method: lasso # 'lasso', 'rfe'
      # Recursive Feature Elimination (rfe) uses the model from parameter model.model as a base model,
      # e.g., PoissonGLM.
    random_seed: 0
    params:
      lasso: # applies when method is 'lasso'
        alpha: 0.001 # the regularization parameter
      rfe: # applies when method is 'rfe'
        estimator_kwargs: # the dictionary of parameters for the estimator
          fit_kwargs:
            max_iter: 10
  hyperopt:
    enabled: True # whether to use the hyperopt
    metric: poisson_deviance # 'poisson_deviance', 'weighted_poisson_deviance',
      # 'gamma_deviance', 'weighted_gamma_deviance', 'rmse', 'weighted_rmse', 'r2', 'weighted_r2',
      # 'gini', 'weighted_gini', 'spearman_correlation', 'weighted_spearman_correlation'
      # tweedie_deviance(p), where p is a float number, e.g., tweedie_deviance(1.5)
      # weighted_tweedie_deviance(p), where p is a float number, e.g., weighted_tweedie_deviance(1.5)
    max_evals: 20 # the maximum number of evaluations
    algo: tpe # 'tpe', 'random'
    show_progressbar: True # whether to show the progress bar
    trial_verbose: True # whether to show each trial in the console
    random_seed: 0 # the random seed for the hyperopt fmin function
    cross_validation:
      enabled: True # whether to use cross-validation
      folds: 10 # the number of folds in cross-validation
      # val_size = 1 / folds
      # train_size = 1 - val_size
    split_val_size: 0.2 # the part of data used for validation â€“ used only if cross_validation.enabled is False
    split_random_seed: 0 # the random seed for splitting the data into train and validation sets
    excluded_params:
#      GradientBoostingRegressor:
#        - n_estimators
  model:
    random_seed: 0
    model_class: # model_class: str, e.g.,
                 # model_class: claim_models.pipelines.p07_data_science.models.SklearnPoissonGLM
                 # if empty, the model class is inferred from the parameter model.model
    const_hparams:
#      SklearnPoissonGLM:
#        alpha: 1
#        fit_intercept: True
#      GradientBoostingRegressor:
#        n_estimators: 100


calibration:
  mlflow_run_id: # If provided a MLFLow run id, the calibration model is saved to / downloaded from the MLflow run
  enabled: True # whether to use the calibration
  method: SklearnPoissonGLM # the method of calibrating pure predictions of data science model from the previous stage
    # 'IsotonicRegression', 'CenteredIsotonicRegression', 'SklearnPoissonGLM'
  lower_bound:
  upper_bound: 1000


test:
  lower_bound:
  upper_bound: 1000
